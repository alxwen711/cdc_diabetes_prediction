{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69fb911c",
   "metadata": {},
   "source": [
    "# Diabetes Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a432974-be85-4068-a432-1be3da071691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandera.pandas as pa\n",
    "import altair as alt\n",
    "import os\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, make_scorer, fbeta_score, \n",
    "    recall_score, precision_score, ConfusionMatrixDisplay\n",
    ")\n",
    "from deepchecks.tabular.checks import FeatureLabelCorrelation, FeatureFeatureCorrelation\n",
    "from deepchecks.tabular import Dataset\n",
    "\n",
    "alt.data_transformers.disable_max_rows()\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"deepchecks\")\n",
    "\n",
    "np.random.seed(522)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47664e6",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0dd468",
   "metadata": {},
   "source": [
    "In this project we attempt to build a model to predict diabetes disease. We compared a decision tree model and naive bayes model and found the decision tree is stronger in this context. We used f2-score as our scoring function because detecting diabetes is the priority: a false negative could be much worse then a false positive.\n",
    "\n",
    "In the test dataset: the decision tree model correctly detected 8283 of 10604 positive cases (recall rate is about 78%). This result does come at a fairly significant cost in terms of false positives (precision rate is about 30%) with 19650 false positives. Depending on the actual cost of false positive this may need significant improvement to be a viable screening model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e388ad9c",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b2ff12",
   "metadata": {},
   "source": [
    "In Canada and the USA approximately 10% of people are living with diabetes. In Canada in 2023 approximately 3.7 million people were living with diabetes and in the USA in 2021 approzimately 38.4 million people were living with diabetes. In the USA it is the 8th leading cause of death. Globally an estimated 44% of people living with diabetes are undiagnosed. (Snapshot of Diabetes in Canada, 2023; Rios et al., 2017; Stafford et al., 2025)\n",
    "\n",
    "In this project we try to predicted diabetes disease based on common health factors. A reliable model could help to prescreen people and recommend following up with a physician for people who are at risk. Given the large number of people living with undiagnosed diabetes this could potentially have a significant positive impact of world health.\n",
    "\n",
    "The analysis uses the American CDC Behavioural Risk Factor Surveillance System (BRFSS) 2015 Diabetes Health Indicators dataset (UCI ID 891), containing 253,680 survey responses with 21 health-related features and a binary diabetes outcome (0 = no diabetes/pre-diabetes, 1 = diabetes).  \n",
    "No missing values were present and all features were already encoded numerically. The target classes is imbalanced (≈86% non-diabetic, ≈14% diabetic)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70729eb",
   "metadata": {},
   "source": [
    "## Methods and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435cdfeb-e4bf-4a3d-b3aa-ca17466cd046",
   "metadata": {},
   "source": [
    "The analysis uses the CDC Behavioural Risk Factor Surveillance System (BRFSS) 2015 Diabetes Health Indicators dataset (UCI ID 891), containing 253,680 survey responses with 21 health-related features and a binary diabetes outcome (0 = no diabetes/pre-diabetes, 1 = diabetes). (Dane and Teboul, 2021) \n",
    "No missing values were present and all features were already encoded numerically. The target classes are heavily imbalanced (≈86% non-diabetic, ≈14% diabetic).\n",
    "\n",
    "### EDA\n",
    "Group-wise mean differences revealed the strongest risk factors for diabetes:\n",
    "- PhysHlth (days of poor physical health)\n",
    "- BMI\n",
    "- Age\n",
    "- MentHlth (days of poor mental health)\n",
    "- GenHlth (self-rated general health)\n",
    "\n",
    "Weakest factors\n",
    "- HvyAlcoholConsump\n",
    "- Fruits\n",
    "- Veggies\n",
    "- PhysActivity\n",
    "- Education\n",
    "- Income\n",
    "\n",
    "Box plots of the top five predictors clearly separate the diabetic and non-diabetic groups.\n",
    "\n",
    "### Modeling Approach\n",
    "The data were split 70/30 into training and test sets with stratification on the target.  \n",
    "Two classifiers were trained and tuned using 5-fold cross-validated grid search with **f2-score** as the scoring metric. We chose to use f2-score because it is more appropriate than accuracy or f1 because we don't want to miss true positives.\n",
    "\n",
    "1. **Decision Tree** (class_weight='balanced')  \n",
    "   Hyperparameters: max_depth ∈ {6,8,10,12,14}, min_samples_leaf ∈ {175, 200, 225, 250}  \n",
    "   **Best parameters**: max_depth=10, min_samples_leaf=200  \n",
    "   **Best CV f2-score** = 0.5908\n",
    "\n",
    "2. **Bernoulli Naive Bayes** (with StandardScaler preprocessing)  \n",
    "   Hyperparameters: alpha ∈ {1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3, 1e4}  \n",
    "   **Best parameters**: alpha=1e-3  \n",
    "   **Best CV f2-score** = 0.4453\n",
    "\n",
    "### Results\n",
    "|         Model | Test Accuracy | Test f2-score | Test recall | Test precision |\n",
    "|--------------:|--------------:|--------------:|------------:|---------------:|\n",
    "| Decision Tree |        0.706 |    **0.587** |  **0.783** |         0.293 |\n",
    "|   Naive Bayes |    **0.814** |        0.460 |      0.489 |     **0.373** |\n",
    "\n",
    "Table: 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea0b4f6",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ba8883-8f50-497e-aceb-92313806dae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset \n",
    "cdc_diabetes_health_indicators = fetch_ucirepo(id=891) \n",
    "\n",
    "# data (as pandas dataframes) \n",
    "X = cdc_diabetes_health_indicators.data.features \n",
    "y = cdc_diabetes_health_indicators.data.targets "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16337a90",
   "metadata": {},
   "source": [
    "## Validate Data Before Saving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4e7a82",
   "metadata": {},
   "source": [
    "### X Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d2cede",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Checks verified:\n",
    "Correct data file format\n",
    "Correct column names\n",
    "No empty observations (and by extension Missingness not beyond expected threshold)\n",
    "Correct data types in each column\n",
    "No outlier or anomalous values\n",
    "\n",
    "Maximum allowable ranges for the numeric_features were determined from\n",
    "the schema description in https://archive.ics.uci.edu/dataset/891/cdc+diabetes+health+indicators.\n",
    "\"\"\"\n",
    "\n",
    "# Check that X is a Pandas DataFrame\n",
    "if not isinstance(X, pd.DataFrame):\n",
    "    raise TypeError(\"X object obtained is not a Pandas Dataframe.\")\n",
    "\n",
    "# Create a list of expected column names\n",
    "column_names = [\"HighBP\",\"HighChol\",\"CholCheck\",\"BMI\",\"Smoker\",\"Stroke\",\"HeartDiseaseorAttack\",\"PhysActivity\",\n",
    "                \"Fruits\",\"Veggies\",\"HvyAlcoholConsump\",\"AnyHealthcare\",\n",
    "                \"NoDocbcCost\",\"GenHlth\",\"MentHlth\",\"PhysHlth\",\"DiffWalk\",\"Sex\",\"Age\",\"Education\",\"Income\"]\n",
    "\n",
    "# Create a list of column names that are binary features\n",
    "binary_features = [\"HighBP\",\"HighChol\",\"CholCheck\",\"Smoker\",\"Stroke\",\"HeartDiseaseorAttack\",\"PhysActivity\",\n",
    "                \"Fruits\",\"Veggies\",\"HvyAlcoholConsump\",\"AnyHealthcare\",\n",
    "                \"NoDocbcCost\",\"DiffWalk\",\"Sex\"]\n",
    "\n",
    "# Define allowable ranges for numeric features\n",
    "numeric_features = {\"BMI\": (5,256),\n",
    "                    \"GenHlth\": (1,5),\n",
    "                    \"MentHlth\": (0,30),\n",
    "                    \"PhysHlth\": (0,30),\n",
    "                    \"Age\": (1,13),\n",
    "                    \"Education\": (1,6),\n",
    "                    \"Income\": (1,8)}\n",
    "\n",
    "# Check that all expected columns are present\n",
    "schema_dict = {}\n",
    "for col_name in binary_features:\n",
    "    schema_dict[col_name] = pa.Column(int, pa.Check.between(0,1), nullable = False)\n",
    "\n",
    "# Add numeric features to schema with their respective ranges\n",
    "for col_name in numeric_features.keys():\n",
    "    schema_dict[col_name] = pa.Column(int, pa.Check.between(numeric_features[col_name][0],numeric_features[col_name][1]), nullable = False)\n",
    "\n",
    "schema = pa.DataFrameSchema(schema_dict)\n",
    "\n",
    "schema.validate(X, lazy = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d3a341",
   "metadata": {},
   "source": [
    "### Y Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cf7c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use same template as X verification, only one column\n",
    "if not isinstance(y, pd.DataFrame):\n",
    "    raise TypeError(\"y object obtained is not a Pandas Dataframe.\")\n",
    "\n",
    "\n",
    "schema_dict = {}\n",
    "\n",
    "target_name = [\"Diabetes_binary\"]\n",
    "\n",
    "for col_name in target_name:\n",
    "    schema_dict[col_name] = pa.Column(int, pa.Check.between(0,1), nullable = False)\n",
    "\n",
    "schema = pa.DataFrameSchema(schema_dict)\n",
    "\n",
    "schema.validate(y, lazy = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a78ecad",
   "metadata": {},
   "source": [
    "### Save Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa115253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if raw folder exists\n",
    "raw_data_path = \"../data/raw\"\n",
    "\n",
    "if not os.path.exists(raw_data_path):\n",
    "    os.makedirs(raw_data_path)\n",
    "\n",
    "## Save Raw Data\n",
    "X.to_csv(\"../data/raw/diabetes_raw_features.csv\")\n",
    "y.to_csv(\"../data/raw/diabetes_raw_targets.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebea5cef",
   "metadata": {},
   "source": [
    "### Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2484c10d-d854-4e4e-b238-7d80887f11e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No major cleaning needed — dataset is already very clean!\n",
    "# Combine features and targets to get a overview of the full data set\n",
    "df = X.copy()\n",
    "df['diabetes'] = y\n",
    "\n",
    "# Quick info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a322a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba17bf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073f4050",
   "metadata": {},
   "source": [
    "### Data Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c2a204",
   "metadata": {},
   "source": [
    "All the features in this dataset were selected by clinician to be relevent to a person having diabetes. We will use all features in our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c5b93b-e101-46ca-8fed-3af14f0b8085",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4a98a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "These checks ensure data quality by verifying:\n",
    "- Checking if duplicate rows exist in the dataset, preventing redundant data points.\n",
    "  (We are not dropping duplicates automatically to avoid unintentional data loss.)\n",
    "  (For the purpose of this dataset, because we already finished the analysis, we will accept the duplicate if any exist.)\n",
    "- Checking for outlier in (\"BMI\", \"MentHlth\", \"PhysHlth\") columns to see if they have extreme outliers based on the IQR rule,\n",
    "  which helps maintain data integrity and model robustness.\n",
    "  (For the purpose of this dataset, we will accept the outlier value because it is a valid measurement.)\n",
    "- Categorical validation is not applicable for this dataset\n",
    "'''\n",
    "\n",
    "def iqr_outliers(series: pd.Series) -> bool:\n",
    "    \"\"\"Return True if all values are within 1.5 * IQR (no extreme outliers)\"\"\"\n",
    "    Q1 = series.quantile(0.25)\n",
    "    Q3 = series.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return series.between(lower_bound, upper_bound).all()\n",
    "\n",
    "\n",
    "# Define the schema with meaningful checks\n",
    "diabetes_schema = pa.DataFrameSchema(\n",
    "    columns={\n",
    "        \"BMI\": pa.Column(float, nullable=False),\n",
    "        \"MentHlth\": pa.Column(float, nullable=False),\n",
    "        \"PhysHlth\": pa.Column(float, nullable=False),\n",
    "    },\n",
    "    checks=[\n",
    "        # 1. No duplicate rows\n",
    "        pa.Check(\n",
    "            lambda df: ~df.duplicated().any(),\n",
    "            error=\"DUPLICATE_ROWS: Found duplicate observations. Use df.drop_duplicates() to remove them.\"\n",
    "        ),\n",
    "        \n",
    "        # 2. No extreme outliers in continuous variables using IQR rule\n",
    "        pa.Check(\n",
    "            lambda df: iqr_outliers(df[\"BMI\"]),\n",
    "            error=\"OUTLIERS_IN_BMI: Extreme outliers detected in BMI (beyond 1.5 × IQR). Consider winsorizing or removing.\"\n",
    "        ),\n",
    "        pa.Check(\n",
    "            lambda df: iqr_outliers(df[\"MentHlth\"]),\n",
    "            error=\"OUTLIERS_IN_MENTHLTH: Extreme values in MentHlth (beyond 1.5 × IQR).\"\n",
    "        ),\n",
    "        pa.Check(\n",
    "            lambda df: iqr_outliers(df[\"PhysHlth\"]),\n",
    "            error=\"OUTLIERS_IN_PHYSHLTH: Extreme values in PhysHlth (beyond 1.5 × IQR).\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Validate with lazy=True to see all errors at once\n",
    "try:\n",
    "    diabetes_schema.validate(df, lazy=True)\n",
    "    print(\"All checks passed! Dataset is clean and ready for modeling.\")\n",
    "except pa.errors.SchemaErrors as e:\n",
    "    print(\"Validation failed! See errors below:\")\n",
    "    print(e.failure_cases)  # Shows detailed failure report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d675bb",
   "metadata": {},
   "source": [
    "### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1ea28c-e06c-4961-87e6-20f4872e3f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_count = pd.DataFrame(df['diabetes'].value_counts()).reset_index()\n",
    "\n",
    "alt.Chart(diabetes_count).mark_bar().encode(\n",
    "    x=alt.X('diabetes:O', title='Has Diabetes'),\n",
    "    y=\"count\",\n",
    "    color=\"diabetes:N\"\n",
    ").properties(title='Count of Diabetes vs Non-Diabetes Recores in Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b97a76",
   "metadata": {},
   "source": [
    "Figure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c840c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df.sample(n=1000, random_state=522)\n",
    "features = df_sample.columns.to_list()\n",
    "df_sample_long = pd.melt(df_sample, id_vars=[\"diabetes\"], value_vars=features[:-1], var_name=\"feature\", value_name=\"feature_value\") \n",
    "\n",
    "histograms = alt.Chart(df_sample_long).mark_bar().encode(\n",
    "    x=alt.X(\"feature_value:O\"), # Chose to use ordinal instead of quantitative because this works better for most features\n",
    "    y=alt.Y(\"count()\", title=\"Count\").stack(False),\n",
    "    color=alt.Color(\"diabetes:N\"),\n",
    ").properties(\n",
    "    width=150,\n",
    "    height=150,\n",
    ").facet(\n",
    "    \"feature:N\",\n",
    "    columns=3,\n",
    ").resolve_scale(\n",
    "    x=\"independent\",\n",
    "    y=\"independent\",   \n",
    ").properties(\n",
    "    title='Histograms of Features',\n",
    ")\n",
    "\n",
    "histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695fa8d9",
   "metadata": {},
   "source": [
    "Figure 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ba2cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For binary features boxplot is not infomative\n",
    "non_binary_features = ['BMI', 'GenHlth', 'MentHlth', 'PhysHlth', 'Age', 'Education', 'Income']\n",
    "df_sample_nonbinary = df_sample_long[df_sample_long[\"feature\"].isin(non_binary_features)]\n",
    "\n",
    "alt.Chart(df_sample_nonbinary).mark_boxplot().encode(\n",
    "    x='diabetes:N',\n",
    "    y='feature_value:Q',\n",
    "    color='diabetes:N'\n",
    ").facet(\n",
    "    column='feature:N'\n",
    ").properties(\n",
    "    title='Boxplots for Non-Binary Features',\n",
    ").resolve_scale(\n",
    "    y=\"independent\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537e3b13",
   "metadata": {},
   "source": [
    "Figure 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7054f69-f6e5-4e59-ab61-4b182f062453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data 70-30 split\n",
    "train_df, test_df = train_test_split(\n",
    "    df, test_size=0.3, random_state=522, stratify=df['diabetes']\n",
    ")\n",
    "\n",
    "# check if processed folder exists\n",
    "processed_data_path = \"../data/processed\"\n",
    "\n",
    "if not os.path.exists(processed_data_path):\n",
    "    os.makedirs(processed_data_path)\n",
    "\n",
    "# Save processed data\n",
    "train_df.to_csv(processed_data_path+\"/diabetes_train.csv\", index=False)\n",
    "test_df.to_csv(processed_data_path+\"/diabetes_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744f30c4-10e8-426d-a9f7-3be9c16bd98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop('diabetes', axis=1)\n",
    "y_train = train_df['diabetes']\n",
    "X_test  = test_df.drop('diabetes', axis=1)\n",
    "y_test  = test_df['diabetes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba64ded2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "- Target/response variable follows expected distribution\n",
    "  (In the diabetes dataset, we expect the prevalence of diabetes to be around 13-15%.)\n",
    "  \n",
    "Validate training data for anomalous correlations:\n",
    "- Feature-label correlations (target vs features)\n",
    "- Feature-feature correlations (between features)\n",
    "\n",
    "Thresholds set based on domain knowledge.\n",
    "\n",
    "We perform these checks on training data only because including test data here could lead to data leakage \n",
    "and invalidate the evaluation of model generalization.\n",
    "'''\n",
    "\n",
    "# Target variable follows expected distribution\n",
    "# In this dataset: ~13–15% diabetes is normal, >30% or <5% is suspicious\n",
    "\n",
    "distribution_schema = pa.DataFrameSchema(\n",
    "    checks=[pa.Check(\n",
    "        lambda df: df.mean().between(0.05, 0.30),\n",
    "        error=\"ANOMALOUS_TARGET_DISTRIBUTION: Diabetes prevalence should be 5–30% (actual: {:.1%})\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "distribution_schema.validate(train_df[['diabetes']], lazy=True)\n",
    "\n",
    "# Combine features and target into a dataset for validation\n",
    "diabetes_train_ds = Dataset(\n",
    "    df=train_df,   \n",
    "    label=\"diabetes\",                          \n",
    "    cat_features=[]\n",
    ")\n",
    "\n",
    "# Check that feature-label predictive power score (PPS) is below 0.9\n",
    "check_feat_lab_corr = FeatureLabelCorrelation().add_condition_feature_pps_less_than(0.9)\n",
    "check_feat_lab_corr_result = check_feat_lab_corr.run(diabetes_train_ds)\n",
    "\n",
    "# Check that no feature pairs have correlation above 0.92\n",
    "check_feat_feat_corr = FeatureFeatureCorrelation().add_condition_max_number_of_pairs_above_threshold(\n",
    "    threshold=0.92, n_pairs=0   \n",
    ")\n",
    "check_feat_feat_corr_result = check_feat_feat_corr.run(diabetes_train_ds)\n",
    "\n",
    "# Raise errors if any checks fail\n",
    "if not check_feat_lab_corr_result.passed_conditions():\n",
    "    raise ValueError(\"Feature-Label correlation exceeds the maximum acceptable threshold.\")\n",
    "\n",
    "if not check_feat_feat_corr_result.passed_conditions():\n",
    "    raise ValueError(\"Feature-feature correlation exceeds the maximum acceptable threshold.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a50c7a9",
   "metadata": {},
   "source": [
    "### Classification Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e31a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f2_scorer = make_scorer(fbeta_score, beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2d81d0-b074-40a2-b283-580ac8d56bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(random_state=522, class_weight='balanced')\n",
    "\n",
    "tree_params = {\n",
    "    'max_depth': [6, 8, 10, 12, 14],\n",
    "    'min_samples_leaf': [175, 200, 225, 250]\n",
    "}\n",
    "\n",
    "tree_grid = GridSearchCV(tree, tree_params, cv=5, scoring=f2_scorer, n_jobs=1)\n",
    "tree_grid.fit(X_train, y_train)\n",
    "\n",
    "best_tree = tree_grid.best_estimator_\n",
    "print(\"Best Decision Tree params:\", tree_grid.best_params_)\n",
    "print(\"Best CV f2-score:\", tree_grid.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d7043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = make_column_transformer(\n",
    "    (StandardScaler(), X_train.columns)\n",
    ")\n",
    "\n",
    "nb_pipe = make_pipeline(\n",
    "    preprocessor,\n",
    "    BernoulliNB()\n",
    ")\n",
    "\n",
    "nb_params = {'bernoullinb__alpha': [1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3, 1e4]}\n",
    "\n",
    "knn_grid = GridSearchCV(nb_pipe, nb_params, cv=5, scoring=f2_scorer, n_jobs=1)\n",
    "knn_grid.fit(X_train, y_train)\n",
    "\n",
    "best_nb = knn_grid.best_estimator_\n",
    "print(\"Best NB k:\", knn_grid.best_params_)\n",
    "print(\"Best CV f2-score:\", knn_grid.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09eb887-aa43-4c5c-b8f0-87a9780b3fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Decision Tree': best_tree,\n",
    "    'Naive Bayes': best_nb\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Test Accuracy': round(accuracy_score(y_test, y_pred),3),\n",
    "        'Test f2-score': round(fbeta_score(y_test, y_pred, beta=2),3),\n",
    "        'Test recall': round(recall_score(y_test, y_pred),3),\n",
    "        'Test precision': round(precision_score(y_test, y_pred),3),\n",
    "    })\n",
    "\n",
    "score_df = pd.DataFrame(results)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b797a75",
   "metadata": {},
   "source": [
    "### Result Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f6c778-d3a1-48e4-968e-b2dc6f5e92bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_melt = score_df.melt(id_vars='Model', var_name='Metric', value_name='Score')\n",
    "\n",
    "alt.Chart(score_melt).mark_bar().encode(\n",
    "    x='Model:N',\n",
    "    y='Score:Q',\n",
    "    color='Model:N',\n",
    "    column='Metric:N'\n",
    ").properties(\n",
    "    title='Decision Tree vs Naive Bayes Performance on Test Set'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9cc0a1",
   "metadata": {},
   "source": [
    "Figure 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df975528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for best model (decision tree)\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(\n",
    "    best_tree,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    values_format=\"d\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcb618e",
   "metadata": {},
   "source": [
    "Figure 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92ac37b",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf2224a",
   "metadata": {},
   "source": [
    "The current performance of the tree model is likely already good enough to offer some benefit in the real world given the large number of people with undiagnosed diabetes. However the the recall score likely could be impoved on and the precision score definitely leaves something to be desired. \n",
    "\n",
    "We were surprised by the high rate of false positives. This might be an indication of how many non-diabetic people are at risk.\n",
    "\n",
    "Further improvements to predicting diabetes could likely be found by 1) trying a wider veriety of model type and using a wider hyperperameter search 2) possibly through more feature engineering. \n",
    "\n",
    "A future study could be done to find a smaller set of the most easy to obtain features. Such a model would be more usable by the average person. Some work is needed to determine this smaller number of easy to obtain features that doesn't significantly reduce model performance.\n",
    "\n",
    "Another question is if a regression model could be made that predicts a persons risk as a percent chance of developing diabetes. Longitudinal data might be required for this type of prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639543ba",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a925e0",
   "metadata": {},
   "source": [
    "Dane, Sohier, and Alex Teboul. Diabetes Health Indicators Dataset. 2021, https://www.kaggle.com/datasets/alexteboul/diabetes-health-indicators-dataset/data.\n",
    "\n",
    "Kelly, Markelle, et al. The UCI Machine Learning Repository. 2021, Utilized the ucimlrepo library for data access. Further documentation on the libraryis located at https://github.com/uci-ml-repo/ucimlrepo.archive.ics.uci.edu/ml.\n",
    "\n",
    "Python 3.12.12 documentation. 2021-2025, https://docs.python.org/3.12/reference/index.html.\n",
    "\n",
    "Rios, Nilka Burrows, et al. Incidence of End-Stage Renal Disease Attributed to Diabetes Among Persons with Diagnosed Diabetes — United States and Puerto Rico. Morb Mortal Wkly Rep, 66(43), Nov. 2017, http://dx.doi.org/10.15585/mmwr.mm6643a2, pp. 1165–70.\n",
    "\n",
    "Snapshot of Diabetes in Canada, 2023. 2023, https://www.canada.ca/en/public-health/services/publications/diseases-conditions/snapshot-diabetes-canada-2023.html.\n",
    "\n",
    "Stafford, Lauryn K, et al. “Global, regional, and national cascades of diabetes care, 2000–23: a systematic review and modelling analysis using findings from the Global Burden of Disease Study”. The Lancet Diabetes & Endocrinology, 13(11), 2025, https://doi.org/10.1016/S2213-8587(25)00217-7, pp. 924–34.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cdc_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
