```{python}
import pickle
import pandas as pd
```

The data were split 70/30 into training and test sets with stratification on the target to preserve the ~14% positive class in both sets. We trained two classifiers and tuned hyperparameters with 5‑fold cross‑validated grid search to obtain stable out‑of‑sample estimates while keeping computational cost reasonable. We optimized models using the **F2-score** because this screening task prioritizes recall: missing true positives is considered substantially worse than flagging false positives. (F2 weights recall twice as much as precision.) During training we applied simple, appropriate preprocessing (e.g., StandardScaler for the Naive Bayes pipeline) and used imbalance-aware settings where applicable (e.g., class_weight='balanced' for the decision tree). After model selection, operating thresholds can be adjusted on precision–recall curves to match practical trade‑offs between false positives and false negatives.

```{python}
with open("../results/models/tree_model.pickle", 'rb') as f:
        model_dt = pickle.load(f)
with open("../results/models/naive_bayes_model.pickle", 'rb') as f:
        model_nb = pickle.load(f)
result_metrics = pd.read_csv("../results/tables/model_scores.csv")

dt_max_depth = model_dt.max_depth
dt_min_samples_leaf = model_dt.min_samples_leaf
dt_f2 = result_metrics[result_metrics["Model"]=="Decision Tree"]["Test f2-score"].values[0]

nb_alpha = model_nb.named_steps["bernoullinb"].alpha
nb_f2 = result_metrics[result_metrics["Model"]=="Naive Bayes"]["Test f2-score"].values[0]
```

1. **Decision Tree** (class_weight='balanced')  
   Hyperparameters: max_depth: {6,8,10,12,14}, min_samples_leaf: {175, 200, 225, 250}  
   **Best parameters**: max_depth=`{python} dt_max_depth`, min_samples_leaf=`{python} dt_min_samples_leaf`  
   **Best CV f2-score** = `{python} dt_f2`  

2. **Bernoulli Naive Bayes** (with StandardScaler preprocessing)  
   Hyperparameters: alpha: {1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3, 1e4}  
   **Best parameters**: alpha=`{python} nb_alpha`  
   **Best CV f2-score** = `{python} nb_f2`  

